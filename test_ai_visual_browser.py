"""
æµ‹è¯• AI è§†è§‰æµè§ˆå™¨
"""

import logging
from ai_visual_browser import AIVisualBrowser

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def test_basic_browsing():
    """æµ‹è¯•åŸºæœ¬æµè§ˆåŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯• AI è§†è§‰æµè§ˆå™¨")
    print("=" * 60)
    
    # æµ‹è¯• URL
    test_url = "https://auctions.stacksbowers.com/auctions/3-1NZHVT/december-2025-collectors-choice-online-auction-tokens-medals-lots-70001-70475"
    
    # æµ‹è¯•æœç´¢è¦æ±‚
    search_queries = [
        "æ‰¾å‡ºæ‰€æœ‰é‡‘å¸",
        "find all silver dollars",
        "æˆ‘æƒ³è¦ Morgan ç¡¬å¸"
    ]
    
    with AIVisualBrowser() as browser:
        for query in search_queries:
            print(f"\n{'='*60}")
            print(f"æœç´¢è¦æ±‚: {query}")
            print('='*60)
            
            # æµè§ˆé¡µé¢
            items = browser.browse_auction_page(test_url, query)
            
            print(f"\næ‰¾åˆ° {len(items)} ä¸ªç¬¦åˆè¦æ±‚çš„æ‹å“:\n")
            
            for i, item in enumerate(items[:5], 1):  # åªæ˜¾ç¤ºå‰ 5 ä¸ª
                print(f"{i}. {item.get('title', 'N/A')}")
                print(f"   ç¼–å·: {item.get('lot_number', 'N/A')}")
                print(f"   ä»·æ ¼: ${item.get('price', 'N/A')}")
                print(f"   ç›¸å…³æ€§: {item.get('relevance_score', 0)}/10")
                print(f"   ç†ç”±: {item.get('reason', 'N/A')}")
                print()
            
            if len(items) > 5:
                print(f"   ... è¿˜æœ‰ {len(items) - 5} ä¸ªæ‹å“")
            
            print()

def test_multi_page_browsing():
    """æµ‹è¯•å¤šé¡µé¢æµè§ˆ"""
    print("=" * 60)
    print("æµ‹è¯•å¤šé¡µé¢æµè§ˆ")
    print("=" * 60)
    
    test_url = "https://auctions.stacksbowers.com/auctions/3-1NZHVT/december-2025-collectors-choice-online-auction-tokens-medals-lots-70001-70475"
    search_query = "æ‰¾å‡ºæ‰€æœ‰åŒ…å«'silver'çš„æ‹å“"
    
    with AIVisualBrowser() as browser:
        items = browser.browse_multiple_pages(
            test_url, 
            search_query,
            max_pages=2
        )
        
        print(f"\næ€»å…±æ‰¾åˆ° {len(items)} ä¸ªç¬¦åˆè¦æ±‚çš„æ‹å“")
        
        # æŒ‰ç›¸å…³æ€§æ’åº
        items_sorted = sorted(
            items, 
            key=lambda x: x.get('relevance_score', 0), 
            reverse=True
        )
        
        print("\næœ€ç›¸å…³çš„ 5 ä¸ªæ‹å“:")
        for i, item in enumerate(items_sorted[:5], 1):
            print(f"{i}. {item.get('title', 'N/A')} (è¯„åˆ†: {item.get('relevance_score', 0)}/10)")

if __name__ == "__main__":
    print("\n")
    print("ğŸ§ª æµ‹è¯• AI è§†è§‰æµè§ˆå™¨")
    print("=" * 60)
    print()
    
    try:
        # æµ‹è¯•åŸºæœ¬æµè§ˆ
        test_basic_browsing()
        
        print("\n\n")
        
        # æµ‹è¯•å¤šé¡µé¢æµè§ˆ
        # test_multi_page_browsing()  # æš‚æ—¶æ³¨é‡Šï¼Œé¿å…å¤ªå¤šè¯·æ±‚
        
        print("\n")
        print("âœ… æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
